# OldRus Anomaly Lab

Проект для поиска смысловых аномалий в древнерусских и церковнославянских текстах: пропуски слов и неуместные замены.
Реализован воспроизводимый пайплайн с генерацией синтетических ошибок, обучением базовых моделей и сохранением метрик.

## Назначение

- автоматический анализ рукописных и оцифрованных текстов с ошибками переписчика
- выявление двух типов аномалий: пропуски и замены
- подготовка отчетных артефактов и наглядных примеров для НИР

## Требования и установка

- Python 3.10+ (рекомендуется 3.11)
- Windows/Linux/macOS

Установка зависимостей:

```bash
python -m pip install -r requirements.txt
```

## Быстрый запуск

Пример с .docx:

```bash
python run_experiment.py --input_docx "data/Гим Воскр 110_Copy.docx" "data/P1032_Copy.docx" --artifacts_dir artifacts --seed 42
```

Пример с .txt (можно передавать несколько файлов):

```bash
python run_experiment.py --input_txt data/my_corpus.txt --artifacts_dir artifacts --seed 42
```

## Modern sanity-check (современный корпус)

Для sanity-check на большом современном русском тексте используйте отдельный скрипт
`run_experiment_modern.py`. Он запускает тот же пайплайн, но сохраняет артефакты
в отдельную папку (`artifacts_modern/`) и помечает `metrics.json` полем
`corpus_type: "modern_russian"`, чтобы результаты не смешивались с основным
экспериментом.

1. Скачайте большой современный русский текст в `.txt` (например, Л. Н. Толстой:
   «Война и мир», «Анна Каренина», «Воскресение») и сохраните в
   `data/modern_russian.txt`.
2. Запустите эксперимент:

```bash
python run_experiment_modern.py
```

Или укажите свой файл и папку артефактов:

```bash
python run_experiment_modern.py --input_txt data/my_corpus.txt --artifacts_dir artifacts_modern --seed 42
```

## Входные данные и предобработка

Поддерживаются форматы:

- .docx: извлечение текста по абзацам, пустые абзацы игнорируются
- .txt: каждая строка рассматривается как отдельный фрагмент, пустые строки разделяют блоки

Нормализация и токенизация:

- удаляются метки вида `<...>` и ссылки вида `1:23`
- унифицируются некоторые знаки пунктуации
- мягкие переносы и спецпробелы заменяются на обычные пробелы
- токены приводятся к нижнему регистру, очищаются от краевой пунктуации
- предложения фильтруются по длине (`--min_tokens`, `--max_tokens`)

## Что делает run_experiment.py

1. Загружает текст из .docx/.txt и нормализует его.
2. Разбивает на предложения и формирует корпус токенов.
3. Делит корпус на train/test.
4. Обучает двунаправленную 3-граммную LM и FastText.
5. Генерирует синтетические ошибки (удаления и замены) в train/test.
6. Извлекает признаки для токенов и промежутков.
7. Обучает логистическую регрессию на токенах (замены).
8. Оценивает качество по PR-кривой и метрикам P/R/F1.
9. Строит список топ-примеров и сохраняет артефакты.

## Параметры эксперимента

Основные:

- `--input_docx`: пути к .docx (можно несколько)
- `--input_txt`: пути к .txt (можно несколько)
- `--artifacts_dir`: папка для результатов (по умолчанию `artifacts`)
- `--seed`: зерно генератора случайных чисел
- `--train_frac`: доля train (по умолчанию 0.75)
- `--min_tokens`, `--max_tokens`: фильтр длины предложения

Синтетические ошибки:

- `--p_delete`: вероятность удаления токена (по умолчанию 0.15)
- `--p_substitute`: вероятность замены токена (по умолчанию 0.15)
- `--max_events`: максимум изменений на предложение
- `--prefer_confusable`: замены подбираются по близости Левенштейна

Модели:

- `--lm_alpha`: add-alpha сглаживание для LM (по умолчанию 0.1)
- `--ft_dim`: размерность FastText (по умолчанию 100)
- `--ft_window`: окно контекста FastText (по умолчанию 5)
- `--ft_bucket`: размер n-граммного словаря FastText (по умолчанию 50000)
- `--ft_epochs`: число эпох FastText (по умолчанию 40)
- `--top_vocab_n`: размер словаря для подсказок (по умолчанию 3000)
- `--top_examples`: число примеров в отчете (по умолчанию 15)

## Артефакты эксперимента

Все файлы сохраняются в папку `artifacts/`:

- `corpus_sentences.jsonl`: нормализованные предложения
- `train_sentences.jsonl`, `test_sentences.jsonl`
- `train_corrupted.jsonl`, `test_corrupted.jsonl`: синтетические ошибки и разметка
- `ngram_lm_fwd.pkl`, `ngram_lm_bwd.pkl`: двунаправленная LM
- `fasttext.model`: модель FastText
- `token_classifier.pkl`: логистическая регрессия для замен
- `scores_tokens.csv`: токен-уровневые признаки и скоры
- `scores_gaps.csv`: gap-скоры между соседними токенами
- `metrics.json`: метрики и параметры эксперимента
- `pr_curve.png`: PR-кривая для токен-классификатора
- `top_examples.md`: топ-примеры аномалий с подсказками

В `demo_outputs/` лежат примеры готовых артефактов для демонстрации.

## Анализ результатов

Краткая сводка по метрикам:

```bash
python summarize_metrics.py artifacts/metrics.json
```

## Опционально: MLM/BERT-скоринг

В проекте есть модуль для masked LM (не включен в основной пайплайн). Используется для диагностики,
как сильно отдельные слова выбиваются по pseudo log-likelihood.

Установка:

```bash
python -m pip install transformers tokenizers accelerate
```

Пример запуска демо:

```bash
python bert_demo.py --input_jsonl artifacts/corpus_sentences.jsonl --model npedrazzini/BERTislav --n 5
```

## Структура репозитория

- `src/oldrus_anomaly/`: основная библиотека (нормализация, LM, FastText, синтетические ошибки, оценка)
- `run_experiment.py`: запуск полного эксперимента
- `summarize_metrics.py`: печать краткой сводки по `metrics.json`
- `bert_demo.py`: демонстрация MLM-скоринга
- `data/`: примеры входных .docx
- `demo_outputs/`: пример результатов

## Примечания

- Разметка создается синтетически, поэтому метрики отражают качество на сгенерированных ошибках.
- Для маленьких корпусов результаты нестабильны; скрипт сообщает об этом при запуске.
